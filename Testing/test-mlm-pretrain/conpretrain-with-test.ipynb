{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8215012,"sourceType":"datasetVersion","datasetId":4869078},{"sourceId":58346,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":48882}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers\n!pip install --upgrade torch torchvision torchaudio","metadata":{"id":"lz94Q1h2MABL","outputId":"aa9589b3-bed6-4721-d148-8bc52369edca","ExecuteTime":{"end_time":"2024-04-24T10:41:22.041819Z","start_time":"2024-04-24T10:41:13.353997Z"},"execution":{"iopub.status.busy":"2024-05-30T05:35:04.328794Z","iopub.execute_input":"2024-05-30T05:35:04.329731Z","iopub.status.idle":"2024-05-30T05:35:29.294685Z","shell.execute_reply.started":"2024-05-30T05:35:04.329695Z","shell.execute_reply":"2024-05-30T05:35:29.293385Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.3.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.18.0)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.10/site-packages (from torch) (2.3.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"! pip install wandb","metadata":{"id":"7zr6g_p4ZHIL","outputId":"c7774035-df25-4b00-8bea-3fd00095a890","ExecuteTime":{"end_time":"2024-04-24T10:41:37.638225Z","start_time":"2024-04-24T10:41:22.044815Z"},"execution":{"iopub.status.busy":"2024-05-30T05:35:29.298942Z","iopub.execute_input":"2024-05-30T05:35:29.299285Z","iopub.status.idle":"2024-05-30T05:35:41.502677Z","shell.execute_reply.started":"2024-05-30T05:35:29.299253Z","shell.execute_reply":"2024-05-30T05:35:41.501494Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.6)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.45.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install scikit-learn","metadata":{"ExecuteTime":{"end_time":"2024-04-24T10:44:26.753142Z","start_time":"2024-04-24T10:44:05.463434Z"},"execution":{"iopub.status.busy":"2024-05-30T05:35:41.504381Z","iopub.execute_input":"2024-05-30T05:35:41.504956Z","iopub.status.idle":"2024-05-30T05:35:53.687061Z","shell.execute_reply.started":"2024-05-30T05:35:41.504922Z","shell.execute_reply":"2024-05-30T05:35:53.686008Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install numpy","metadata":{"ExecuteTime":{"end_time":"2024-04-24T10:44:50.540637Z","start_time":"2024-04-24T10:44:39.581043Z"},"execution":{"iopub.status.busy":"2024-05-30T05:35:53.690403Z","iopub.execute_input":"2024-05-30T05:35:53.690832Z","iopub.status.idle":"2024-05-30T05:36:05.960789Z","shell.execute_reply.started":"2024-05-30T05:35:53.690790Z","shell.execute_reply":"2024-05-30T05:36:05.959636Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nimport torch\nimport random\nimport numpy as np\nimport torch.nn as nn\nimport wandb\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, get_linear_schedule_with_warmup, BertForMaskedLM, AutoConfig\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom imblearn.over_sampling import RandomOverSampler\nfrom torch.optim import Adam","metadata":{"id":"nNcjjwSuMF9D","ExecuteTime":{"end_time":"2024-04-24T10:44:55.324248Z","start_time":"2024-04-24T10:44:54.295309Z"},"execution":{"iopub.status.busy":"2024-05-30T05:36:05.962965Z","iopub.execute_input":"2024-05-30T05:36:05.963442Z","iopub.status.idle":"2024-05-30T05:36:05.971837Z","shell.execute_reply.started":"2024-05-30T05:36:05.963395Z","shell.execute_reply":"2024-05-30T05:36:05.970824Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix","metadata":{"id":"tjwvP8S11kp8","ExecuteTime":{"end_time":"2024-04-24T10:46:30.944668Z","start_time":"2024-04-24T10:46:30.933152Z"},"execution":{"iopub.status.busy":"2024-05-30T05:36:05.973355Z","iopub.execute_input":"2024-05-30T05:36:05.973804Z","iopub.status.idle":"2024-05-30T05:36:05.982200Z","shell.execute_reply.started":"2024-05-30T05:36:05.973770Z","shell.execute_reply":"2024-05-30T05:36:05.981224Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"wandb.login(key=\"9b49f600300d891290c544a9d0580ec7b7185a34\")","metadata":{"execution":{"iopub.status.busy":"2024-05-30T05:36:05.983514Z","iopub.execute_input":"2024-05-30T05:36:05.983863Z","iopub.status.idle":"2024-05-30T05:36:05.994859Z","shell.execute_reply.started":"2024-05-30T05:36:05.983831Z","shell.execute_reply":"2024-05-30T05:36:05.993704Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"wandb.init(project='zaloqa-pretrained-bert', entity='hdghung2912')\"\"\"","metadata":{"id":"pgn0EbeNDgHj","outputId":"e422875c-9f7e-4322-cdb1-6749d988a6b7","ExecuteTime":{"end_time":"2024-04-24T10:46:25.625639Z","start_time":"2024-04-24T10:45:26.087532Z"},"execution":{"iopub.status.busy":"2024-05-30T05:36:05.996091Z","iopub.execute_input":"2024-05-30T05:36:05.996356Z","iopub.status.idle":"2024-05-30T05:36:06.013151Z","shell.execute_reply.started":"2024-05-30T05:36:05.996333Z","shell.execute_reply":"2024-05-30T05:36:06.012125Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"\"wandb.init(project='zaloqa-pretrained-bert', entity='hdghung2912')\""},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Load the data from train.json\nwith open('/kaggle/input/traintest/train.json', 'r', encoding='utf-8') as file:\n    data = json.load(file)\n\n# Split the data into train and test sets (85% train, 15% test)\ntrain_data, test_data = train_test_split(data, test_size=0.15, random_state=42)\n\n# Save the train and test data to separate files\nwith open('train_split.json', 'w', encoding='utf-8') as train_file:\n    json.dump(train_data, train_file, ensure_ascii=False, indent=4)\n\nwith open('test_split.json', 'w', encoding='utf-8') as test_file:\n    json.dump(test_data, test_file, ensure_ascii=False, indent=4)\n","metadata":{"id":"RDi39wkIMNZS","outputId":"dee1340e-1fe2-47f3-f4fa-bff82d8772e0","ExecuteTime":{"end_time":"2024-04-24T10:45:05.937501Z","start_time":"2024-04-24T10:45:05.761917Z"},"execution":{"iopub.status.busy":"2024-05-30T05:36:06.014698Z","iopub.execute_input":"2024-05-30T05:36:06.015049Z","iopub.status.idle":"2024-05-30T05:36:06.621073Z","shell.execute_reply.started":"2024-05-30T05:36:06.015016Z","shell.execute_reply":"2024-05-30T05:36:06.619959Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Đọc dữ liệu từ tập tin train_split.json vào biến train_data\nwith open('train_split.json', 'r', encoding='utf-8') as train_file:\n    train_data = json.load(train_file)\n\n# Đọc dữ liệu từ tập tin test_split.json vào biến test_data\nwith open('test_split.json', 'r', encoding='utf-8') as test_file:\n    test_data = json.load(test_file)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T05:36:06.626289Z","iopub.execute_input":"2024-05-30T05:36:06.627091Z","iopub.status.idle":"2024-05-30T05:36:06.810116Z","shell.execute_reply.started":"2024-05-30T05:36:06.627049Z","shell.execute_reply":"2024-05-30T05:36:06.808989Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/traintest/test.json', 'r', encoding='utf-8') as f:\n    cpr = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T05:36:06.811347Z","iopub.execute_input":"2024-05-30T05:36:06.811662Z","iopub.status.idle":"2024-05-30T05:36:06.841600Z","shell.execute_reply.started":"2024-05-30T05:36:06.811636Z","shell.execute_reply":"2024-05-30T05:36:06.840601Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")","metadata":{"execution":{"iopub.status.busy":"2024-05-30T05:36:06.843033Z","iopub.execute_input":"2024-05-30T05:36:06.843437Z","iopub.status.idle":"2024-05-30T05:36:09.161982Z","shell.execute_reply.started":"2024-05-30T05:36:06.843397Z","shell.execute_reply":"2024-05-30T05:36:09.160902Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16eb174b8afe4abeaf4f690a10973b44"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"205f9c372b4949129177597f040cdd1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/3.13M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12e59249cfee4b52ad14730d31522516"}},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_for_pretraining(data, tokenizer):\n    max_question_length=64\n    max_text_length=192\n    input_ids = []\n    attention_masks = []\n\n    for sample in data:\n        question = sample['question']\n        for paragraph in sample['paragraphs']:\n            text = paragraph['text']\n            encoded_question = tokenizer.encode_plus(\n                question,\n                add_special_tokens=True,\n                truncation=True,\n                max_length=max_question_length,\n                padding='max_length',\n                return_attention_mask=True,\n                return_tensors='pt'\n            )\n\n            encoded_text = tokenizer.encode_plus(\n                text,\n                add_special_tokens=True,\n                truncation=True,\n                max_length=max_text_length,\n                padding='max_length',\n                return_attention_mask=True,\n                return_tensors='pt'\n            )\n\n            combined_input_ids = torch.cat((encoded_question['input_ids'], encoded_text['input_ids']), dim=1)\n            combined_attention_mask = torch.cat((encoded_question['attention_mask'], encoded_text['attention_mask']), dim=1)\n\n            input_ids.append(combined_input_ids)\n            attention_masks.append(combined_attention_mask)\n\n    input_ids = torch.cat(input_ids, dim=0)\n    attention_masks = torch.cat(attention_masks, dim=0)\n\n    return input_ids, attention_masks","metadata":{"execution":{"iopub.status.busy":"2024-05-30T05:36:09.163424Z","iopub.execute_input":"2024-05-30T05:36:09.163806Z","iopub.status.idle":"2024-05-30T05:36:09.177295Z","shell.execute_reply.started":"2024-05-30T05:36:09.163773Z","shell.execute_reply":"2024-05-30T05:36:09.176286Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"pretrain_input_ids, pretrain_attention_masks = preprocess_for_pretraining(cpr, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T05:36:09.178659Z","iopub.execute_input":"2024-05-30T05:36:09.178980Z","iopub.status.idle":"2024-05-30T05:36:11.646271Z","shell.execute_reply.started":"2024-05-30T05:36:09.178946Z","shell.execute_reply":"2024-05-30T05:36:11.645208Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model = BertForMaskedLM.from_pretrained('vinai/phobert-base-v2')\nmodel.to('cuda')\n\n# Khởi tạo optimizer\noptimizer = Adam(model.parameters(), lr=2e-5)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T05:36:11.647551Z","iopub.execute_input":"2024-05-30T05:36:11.647824Z","iopub.status.idle":"2024-05-30T05:36:13.750772Z","shell.execute_reply.started":"2024-05-30T05:36:11.647800Z","shell.execute_reply":"2024-05-30T05:36:13.749810Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\nSome weights of BertForMaskedLM were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"pretrain_dataset = TensorDataset(pretrain_input_ids, pretrain_attention_masks)\npretrain_dataloader = DataLoader(pretrain_dataset, sampler=RandomSampler(pretrain_dataset), batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T05:36:13.752094Z","iopub.execute_input":"2024-05-30T05:36:13.752379Z","iopub.status.idle":"2024-05-30T05:36:13.759877Z","shell.execute_reply.started":"2024-05-30T05:36:13.752355Z","shell.execute_reply":"2024-05-30T05:36:13.758785Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"for batch in pretrain_dataloader:\n    input_ids, attention_masks = batch\n    print(\"Input IDs:\")\n    print(input_ids)\n    print(\"\\nAttention Masks:\")\n    print(attention_masks)\n    # In ra một batch thôi là đủ\n    break","metadata":{"execution":{"iopub.status.busy":"2024-05-30T05:36:13.761239Z","iopub.execute_input":"2024-05-30T05:36:13.761640Z","iopub.status.idle":"2024-05-30T05:36:13.774469Z","shell.execute_reply.started":"2024-05-30T05:36:13.761602Z","shell.execute_reply":"2024-05-30T05:36:13.773407Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Input IDs:\ntensor([[    0,  4983,   943,  ...,     1,     1,     1],\n        [    0,   350,   590,  ...,     1,     1,     1],\n        [    0,  2269,   139,  ...,     1,     1,     1],\n        ...,\n        [    0, 33354,  5442,  ...,     1,     1,     1],\n        [    0, 45107,  2949,  ...,     1,     1,     1],\n        [    0, 13278,   975,  ...,     1,     1,     1]])\n\nAttention Masks:\ntensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0]])\n","output_type":"stream"}]},{"cell_type":"code","source":"def pretrain(model, dataloader, optimizer, device, epochs):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        for step, batch in enumerate(tqdm(dataloader, desc=f\"Pretrain Epoch {epoch + 1}/{epochs}\")):\n            batch_input_ids, batch_attention_masks = tuple(t.to(device) for t in batch)\n\n            model.zero_grad()\n            outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_masks, labels=batch_input_ids)\n            loss = outputs.loss\n            total_loss += loss.item()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n\n            # Log loss cho mỗi batch lên wandb\n            wandb.log({\"pretrain_batch_loss\": loss.item()})\n\n        avg_train_loss = total_loss / len(dataloader)\n        print(f\"Pretrain Epoch {epoch + 1}, Average Training Loss: {avg_train_loss}\")\n\n        # Log average loss cho mỗi epoch lên wandb\n        wandb.log({\"pretrain_epoch\": epoch + 1, \"pretrain_average_loss\": avg_train_loss})\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-30T05:36:13.776070Z","iopub.execute_input":"2024-05-30T05:36:13.776500Z","iopub.status.idle":"2024-05-30T05:36:13.785726Z","shell.execute_reply.started":"2024-05-30T05:36:13.776453Z","shell.execute_reply":"2024-05-30T05:36:13.784678Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"pretrain(model, pretrain_dataloader, optimizer, device='cuda', epochs=8)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T05:36:13.786645Z","iopub.execute_input":"2024-05-30T05:36:13.786959Z","iopub.status.idle":"2024-05-30T06:03:42.918506Z","shell.execute_reply.started":"2024-05-30T05:36:13.786928Z","shell.execute_reply":"2024-05-30T06:03:42.917246Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"Pretrain Epoch 1/8: 100%|██████████| 335/335 [03:25<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Pretrain Epoch 1, Average Training Loss: 1.4559115464117989\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 2/8: 100%|██████████| 335/335 [03:26<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Pretrain Epoch 2, Average Training Loss: 0.270401968929305\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 3/8: 100%|██████████| 335/335 [03:25<00:00,  1.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Pretrain Epoch 3, Average Training Loss: 0.12034877648771698\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 4/8: 100%|██████████| 335/335 [03:26<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Pretrain Epoch 4, Average Training Loss: 0.06885592521571401\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 5/8: 100%|██████████| 335/335 [03:26<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Pretrain Epoch 5, Average Training Loss: 0.04409778899888494\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 6/8: 100%|██████████| 335/335 [03:26<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Pretrain Epoch 6, Average Training Loss: 0.03020225711055656\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 7/8: 100%|██████████| 335/335 [03:26<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Pretrain Epoch 7, Average Training Loss: 0.021577289947934116\n","output_type":"stream"},{"name":"stderr","text":"Pretrain Epoch 8/8: 100%|██████████| 335/335 [03:26<00:00,  1.63it/s]","output_type":"stream"},{"name":"stdout","text":"Pretrain Epoch 8, Average Training Loss: 0.015919152392880685\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Đường dẫn để lưu checkpoint\nsave_path = './results/checkpoint-pretrain'\nmodel.save_pretrained(save_path)\ntokenizer.save_pretrained(save_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T06:17:25.643639Z","iopub.execute_input":"2024-05-30T06:17:25.644370Z","iopub.status.idle":"2024-05-30T06:17:27.275115Z","shell.execute_reply.started":"2024-05-30T06:17:25.644336Z","shell.execute_reply":"2024-05-30T06:17:27.274154Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"('./results/checkpoint-pretrain/tokenizer_config.json',\n './results/checkpoint-pretrain/special_tokens_map.json',\n './results/checkpoint-pretrain/vocab.txt',\n './results/checkpoint-pretrain/bpe.codes',\n './results/checkpoint-pretrain/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"wandb.init(project='zaloqa-bert', entity='hdghung2912')","metadata":{"execution":{"iopub.status.busy":"2024-05-30T06:17:29.338354Z","iopub.execute_input":"2024-05-30T06:17:29.339158Z","iopub.status.idle":"2024-05-30T06:17:51.869444Z","shell.execute_reply.started":"2024-05-30T06:17:29.339126Z","shell.execute_reply":"2024-05-30T06:17:51.868535Z"},"trusted":true},"execution_count":50,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:o0nv2grv) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pretrain_average_loss</td><td>█▂▂▁▁▁▁▁</td></tr><tr><td>pretrain_batch_loss</td><td>█▆▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>pretrain_epoch</td><td>▁▂▃▄▅▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pretrain_average_loss</td><td>0.01592</td></tr><tr><td>pretrain_batch_loss</td><td>0.01955</td></tr><tr><td>pretrain_epoch</td><td>8</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fiery-aardvark-34</strong> at: <a href='https://wandb.ai/hdghung2912/zaloqa-bert/runs/o0nv2grv' target=\"_blank\">https://wandb.ai/hdghung2912/zaloqa-bert/runs/o0nv2grv</a><br/> View project at: <a href='https://wandb.ai/hdghung2912/zaloqa-bert' target=\"_blank\">https://wandb.ai/hdghung2912/zaloqa-bert</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240530_052627-o0nv2grv/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:o0nv2grv). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240530_061729-r3ob9fmj</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/hdghung2912/zaloqa-bert/runs/r3ob9fmj' target=\"_blank\">trim-snowball-35</a></strong> to <a href='https://wandb.ai/hdghung2912/zaloqa-bert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/hdghung2912/zaloqa-bert' target=\"_blank\">https://wandb.ai/hdghung2912/zaloqa-bert</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/hdghung2912/zaloqa-bert/runs/r3ob9fmj' target=\"_blank\">https://wandb.ai/hdghung2912/zaloqa-bert/runs/r3ob9fmj</a>"},"metadata":{}},{"execution_count":50,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/hdghung2912/zaloqa-bert/runs/r3ob9fmj?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7ddaa257c730>"},"metadata":{}}]},{"cell_type":"code","source":"pretrained_path = '/kaggle/input/zalo-pretrained/transformers/checkpoint-pretrained/1'","metadata":{"execution":{"iopub.status.busy":"2024-05-30T06:17:51.871468Z","iopub.execute_input":"2024-05-30T06:17:51.872142Z","iopub.status.idle":"2024-05-30T06:17:51.878002Z","shell.execute_reply.started":"2024-05-30T06:17:51.872105Z","shell.execute_reply":"2024-05-30T06:17:51.877128Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(save_path, num_labels=2)\ntokenizer = AutoTokenizer.from_pretrained(save_path)","metadata":{"id":"2y0UYf94MzG_","outputId":"5eda12c6-4e8a-41a8-e27d-9d974e0dc0ce","ExecuteTime":{"end_time":"2024-04-24T10:45:15.334887Z","start_time":"2024-04-24T10:45:11.728132Z"},"execution":{"iopub.status.busy":"2024-05-30T06:19:20.286343Z","iopub.execute_input":"2024-05-30T06:19:20.287052Z","iopub.status.idle":"2024-05-30T06:19:20.670394Z","shell.execute_reply.started":"2024-05-30T06:19:20.287018Z","shell.execute_reply":"2024-05-30T06:19:20.669434Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./results/checkpoint-pretrain and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_data(data, tokenizer):\n    max_question_length = 64\n    max_text_length = 192\n    input_ids = []\n    attention_masks = []\n    labels = []\n\n    for sample in data:\n        question = sample['question']\n        text = sample['text']\n        label = sample['label']\n        \n        encoded_question = tokenizer.encode_plus(\n            question,\n            add_special_tokens=True,\n            truncation=True,\n            max_length=max_question_length,\n            padding='max_length',\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n\n        encoded_text = tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            truncation=True,\n            max_length=max_text_length,\n            padding='max_length',\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n\n        combined_input_ids = torch.cat((encoded_question['input_ids'], encoded_text['input_ids']), dim=1)\n        combined_attention_mask = torch.cat((encoded_question['attention_mask'], encoded_text['attention_mask']), dim=1)\n\n        input_ids.append(combined_input_ids)\n        attention_masks.append(combined_attention_mask)\n        labels.append(1 if label else 0)\n\n    input_ids = torch.cat(input_ids, dim=0)\n    attention_masks = torch.cat(attention_masks, dim=0)\n    labels = torch.tensor(labels)\n\n    print(f\"Final input_ids shape: {input_ids.shape}\")\n    print(f\"Final attention_masks shape: {attention_masks.shape}\")\n    print(f\"Final labels shape: {labels.shape}\")\n\n    return input_ids, attention_masks, labels\n","metadata":{"id":"HYcbKejvM0ef","ExecuteTime":{"end_time":"2024-04-24T10:45:09.895580Z","start_time":"2024-04-24T10:45:09.880045Z"},"execution":{"iopub.status.busy":"2024-05-30T06:19:34.081364Z","iopub.execute_input":"2024-05-30T06:19:34.081988Z","iopub.status.idle":"2024-05-30T06:19:34.091287Z","shell.execute_reply.started":"2024-05-30T06:19:34.081957Z","shell.execute_reply":"2024-05-30T06:19:34.090465Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"X = [{'question': sample['question'], 'text': sample['text']} for sample in data]\ny = [sample['label'] for sample in data]\n\n# Chia dữ liệu thành tập huấn luyện và tập validation (85-15)\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\n\n# Tạo một RandomOverSampler\nros = RandomOverSampler(random_state=0)\n\n# Resample tập huấn luyện\nX_train_array = np.array([[sample['question'], sample['text']] for sample in X_train])\nX_train_resampled, y_train_resampled = ros.fit_resample(X_train_array, y_train)\n\n# Đảm bảo X_train_resampled và y_train_resampled có cùng số lượng mẫu\nassert len(X_train_resampled) == len(y_train_resampled)\n\n# In ra số lượng nhãn true và false trong tập huấn luyện sau khi resample\nnum_true_resampled_train = sum(1 for label in y_train_resampled if label)\nnum_false_resampled_train = len(y_train_resampled) - num_true_resampled_train\nprint(\"Resampled Train - Number of true labels:\", num_true_resampled_train)\nprint(\"Resampled Train - Number of false labels:\", num_false_resampled_train)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T06:19:35.993241Z","iopub.execute_input":"2024-05-30T06:19:35.993625Z","iopub.status.idle":"2024-05-30T06:19:37.008345Z","shell.execute_reply.started":"2024-05-30T06:19:35.993594Z","shell.execute_reply":"2024-05-30T06:19:37.007173Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"Resampled Train - Number of true labels: 10535\nResampled Train - Number of false labels: 10535\n","output_type":"stream"}]},{"cell_type":"code","source":"resampled_data = [{'question': X_train_resampled[i, 0], 'text': X_train_resampled[i, 1], 'label': y_train_resampled[i]} for i in range(len(X_train_resampled))]","metadata":{"execution":{"iopub.status.busy":"2024-05-30T06:19:37.934047Z","iopub.execute_input":"2024-05-30T06:19:37.934759Z","iopub.status.idle":"2024-05-30T06:19:38.232397Z","shell.execute_reply.started":"2024-05-30T06:19:37.934724Z","shell.execute_reply":"2024-05-30T06:19:38.231601Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    print(f'Question: {X_train_resampled[i, 0]}')\n    print(f'Text: {X_train_resampled[i, 1]}')\n    print(f'Label: {y_train_resampled[i]}')\n    print('---')","metadata":{"execution":{"iopub.status.busy":"2024-05-30T06:19:39.539801Z","iopub.execute_input":"2024-05-30T06:19:39.540593Z","iopub.status.idle":"2024-05-30T06:19:39.548940Z","shell.execute_reply.started":"2024-05-30T06:19:39.540557Z","shell.execute_reply":"2024-05-30T06:19:39.547966Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Question: Sông Nin đổ ra biển nào\nText: Sông Luỹ đổ ra biển ở cửa biển tại thị trấn Phan Rí\nLabel: False\n---\nQuestion: Tên gọi Nhật Bản nghĩa là gì\nText: Từ ghép này có nghĩa là \" nguồn gốc của mặt trời \" hoặc \" nơi mặt trời mọc \" ( từ quan điểm từ Trung Quốc , mặt trời mọc từ phía Nhật Bản ) ; nó là một nguồn cơ sở cho mô tả của phương Tây về Nhật Bản như là \" Vùng đất Mặt trời mọc \" ( \" Land of the Rising Sun \" ) .\nLabel: True\n---\nQuestion: Dầu mỏ có màu gì\nText: Loại dầu khoáng này là dầu trong suốt , không màu bao gồm chủ yếu là ankan và cycloankan , liên quan đến thạch dầu mỏ .\nLabel: False\n---\nQuestion: Huyện đảo Phú Quốc có diện tích bao nhiêu\nText: Hồ tiêu Phú Quốc là một loại gia vị được coi là đặc sản của huyện đảo Phú Quốc thuộc Tỉnh Kiên Giang , Việt Nam .\nLabel: False\n---\nQuestion: Cộng hoà Ireland có biên giới trên bộ với quốc gia nào\nText: Ireland là một quốc gia thành viên Liên minh châu Âu từ năm 1973 , song lựa chọn duy trì bên ngoài khu vực Schengen . Công dân Anh Quốc có thể tự do nhập cảnh Cộng hoà Ireland mà không cần hộ chiếu do hai bên có biên giới mở .\nLabel: False\n---\n","output_type":"stream"}]},{"cell_type":"code","source":"val_data = [{'question': sample['question'], 'text': sample['text'], 'label': label} for sample, label in zip(X_val, y_val)]","metadata":{"execution":{"iopub.status.busy":"2024-05-30T06:19:42.225094Z","iopub.execute_input":"2024-05-30T06:19:42.225458Z","iopub.status.idle":"2024-05-30T06:19:42.233457Z","shell.execute_reply.started":"2024-05-30T06:19:42.225428Z","shell.execute_reply":"2024-05-30T06:19:42.232533Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    print(f'Question: {val_data[i][\"question\"]}')\n    print(f'Text: {val_data[i][\"text\"]}')\n    print(f'Label: {val_data[i][\"label\"]}')\n    print('---')","metadata":{"execution":{"iopub.status.busy":"2024-05-30T06:19:42.997034Z","iopub.execute_input":"2024-05-30T06:19:42.997692Z","iopub.status.idle":"2024-05-30T06:19:43.006849Z","shell.execute_reply.started":"2024-05-30T06:19:42.997657Z","shell.execute_reply":"2024-05-30T06:19:43.005539Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"Question: Lê Lợi với Lê Lai có quan hệ gì\nText: Lê Thái Tổ ở ngôi được 5 năm thì qua đời vào ngày 22 tháng 8 âm lịch (7 tháng 9 dương lịch) năm Quý Sửu (1433), hưởng dương 49 tuổi. Vì nhớ công Lê Lai chết thay cho mình ở núi Chí Linh trước kia, ông dặn lại đời sau phải giỗ Lê Lai trước khi giỗ ông một ngày. Bởi thế đời sau truyền lại câu: \"Hăm mốt Lê Lai, hăm hai Lê Lợi.\"\nLabel: False\n---\nQuestion: ai là phó bí thư hiện tại của Đà Nẵng\nText: Ngày 15 tháng 7 năm 2013 , Thành uỷ Đà Nẵng công bố quyết định số 7340 / QĐ-TU thành lập Ban Nội chính Thành uỷ Đà Nẵng . Ông Trần Thanh Vân , lúc này là Thành uỷ viên Thành uỷ Đà Nẵng , Viện trưởng Viện kiểm sát nhân dân thành phố Đà Nẵng , được điều động , bổ nhiệm làm Trưởng Ban Nội chính Thành uỷ Đà Nẵng nhiệm kì 5 năm , hai Phó ban là Nhật Thành , Phó Trưởng Ban thường trực Ban chỉ đạo Phòng chống tham nhũng thành phố Đà Nẵng và ông Phạm Hà Bắc , Phó Trưởng Ban chỉ đạo phòng chống tham nhũng thành phố Đà Nẵng .\nLabel: False\n---\nQuestion: Ai là tác giả của bài Hịch tướng sĩ\nText: Ngô Tất Tố viết rằng bài Dụ chư tỳ tướng hịch văn cho thấy, không những Hưng Đạo Vương là võ tướng mà ông còn có tài học vấn, đọc nhiều sách và thông hiểu nhiều điển tích cổ kim.\nLabel: False\n---\nQuestion: Quang Trung mất vào ngày tháng năm nào\nText: Dương Quang Trung (sinh ngày 03 tháng 9 năm 1928 mất ngày 22 tháng 6 năm 2013) biệt hiệu Tư Trung là một bác sĩ người Việt Nam.\nLabel: False\n---\nQuestion: Tôn Trung Sơn nhậm chức tổng thống năm nào\nText: Đến mùa đông Tưởng Giới Thạch tuân lệnh nhậm chức Tham mưu trưởng Quân đoàn 2 Đông lộ thảo tặc quân , đến Phúc Kiến lập kế dẹp loạn . Lúc đó , Tôn Trung Sơn phái Tưởng Giới Thạch đi Phúc Kiến , lập liên hệ cùng An Phúc hệ quân phiệt ; dưới sự bang trợ của họ , Tôn Trung Sơn trở về Quảng Châu vào năm 1923 .\nLabel: False\n---\n","output_type":"stream"}]},{"cell_type":"code","source":"train_input_ids, train_attention_masks, train_labels = preprocess_data(resampled_data, tokenizer)\nval_input_ids, val_attention_masks, val_labels = preprocess_data(val_data, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T06:20:30.673334Z","iopub.execute_input":"2024-05-30T06:20:30.673725Z","iopub.status.idle":"2024-05-30T06:20:54.176854Z","shell.execute_reply.started":"2024-05-30T06:20:30.673694Z","shell.execute_reply":"2024-05-30T06:20:54.175916Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"Final input_ids shape: torch.Size([21070, 256])\nFinal attention_masks shape: torch.Size([21070, 256])\nFinal labels shape: torch.Size([21070])\nFinal input_ids shape: torch.Size([2717, 256])\nFinal attention_masks shape: torch.Size([2717, 256])\nFinal labels shape: torch.Size([2717])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Tạo TensorDataset cho tập huấn luyện\ntrain_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n\n# Tạo DataLoader cho tập huấn luyện\ntrain_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=8)\n\n# Tạo TensorDataset cho tập validation\nval_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n\n# Tạo DataLoader cho tập validation\nval_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T06:20:54.178925Z","iopub.execute_input":"2024-05-30T06:20:54.179602Z","iopub.status.idle":"2024-05-30T06:20:54.191614Z","shell.execute_reply.started":"2024-05-30T06:20:54.179565Z","shell.execute_reply":"2024-05-30T06:20:54.190490Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"for batch in train_dataloader:\n    batch_input_ids, batch_attention_masks, batch_labels = batch\n    print(f\"Batch input_ids shape: {batch_input_ids.shape}\")\n    print(f\"Batch attention_masks shape: {batch_attention_masks.shape}\")\n    print(f\"Batch labels shape: {batch_labels.shape}\")\n    break","metadata":{"execution":{"iopub.status.busy":"2024-05-30T06:20:54.192745Z","iopub.execute_input":"2024-05-30T06:20:54.193086Z","iopub.status.idle":"2024-05-30T06:20:54.201236Z","shell.execute_reply.started":"2024-05-30T06:20:54.193053Z","shell.execute_reply":"2024-05-30T06:20:54.200252Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"Batch input_ids shape: torch.Size([8, 256])\nBatch attention_masks shape: torch.Size([8, 256])\nBatch labels shape: torch.Size([8])\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"id":"Yc9SMc2iM-9h","outputId":"81b64bf7-0ae3-49cc-dd22-fc7c1d2ba559","ExecuteTime":{"end_time":"2024-04-24T10:46:25.656875Z","start_time":"2024-04-24T10:46:25.629639Z"},"execution":{"iopub.status.busy":"2024-05-30T06:20:54.202976Z","iopub.execute_input":"2024-05-30T06:20:54.203329Z","iopub.status.idle":"2024-05-30T06:20:54.215944Z","shell.execute_reply.started":"2024-05-30T06:20:54.203304Z","shell.execute_reply":"2024-05-30T06:20:54.215159Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n      (position_embeddings): Embedding(258, 768)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = Adam(model.parameters(), lr=2e-5)\ncriterion = nn.BCEWithLogitsLoss()","metadata":{"id":"FR-0O_4iNBTL","ExecuteTime":{"end_time":"2024-04-24T10:46:27.718729Z","start_time":"2024-04-24T10:46:25.660408Z"},"execution":{"iopub.status.busy":"2024-05-30T06:20:54.216927Z","iopub.execute_input":"2024-05-30T06:20:54.217179Z","iopub.status.idle":"2024-05-30T06:20:54.222726Z","shell.execute_reply.started":"2024-05-30T06:20:54.217157Z","shell.execute_reply":"2024-05-30T06:20:54.221893Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"epochs = 5\ntotal_steps = len(train_dataloader) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T06:21:01.022535Z","iopub.execute_input":"2024-05-30T06:21:01.022866Z","iopub.status.idle":"2024-05-30T06:21:01.031434Z","shell.execute_reply.started":"2024-05-30T06:21:01.022841Z","shell.execute_reply":"2024-05-30T06:21:01.030529Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"def train(model, train_dataloader, epochs, optimizer, scheduler, device):\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch + 1}/{epochs}\")\n        model.train()\n        total_loss = 0\n        correct_preds = 0\n        total_preds = 0\n\n        # Sử dụng tqdm để hiển thị tiến trình huấn luyện\n        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training\")):\n            batch_input_ids, batch_attention_masks, batch_labels = tuple(t.to(device) for t in batch)\n\n            model.zero_grad()\n            outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_masks, labels=batch_labels)\n            loss = outputs.loss\n            total_loss += loss.item()\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            scheduler.step()\n\n            # Tính accuracy\n            logits = outputs.logits\n            preds = torch.argmax(logits, dim=1)\n            correct_preds += torch.sum(preds == batch_labels).item()\n            total_preds += len(batch_labels)\n\n        avg_train_loss = total_loss / len(train_dataloader)\n        train_accuracy = correct_preds / total_preds\n        \n        # Ghi loss và accuracy vào Weights & Biases\n        wandb.log({\"Train Loss\": avg_train_loss, \"Train Accuracy\": train_accuracy})\n\n        print(f\"Epoch {epoch + 1}, Average Training Loss: {avg_train_loss}, Train Accuracy: {train_accuracy}\")","metadata":{"id":"RsyL-OmDD1AL","outputId":"6a7e566b-7b82-420e-ee6c-29f0b8853996","jupyter":{"is_executing":true},"ExecuteTime":{"start_time":"2024-04-24T10:46:32.161352Z"},"execution":{"iopub.status.busy":"2024-05-30T06:21:05.447102Z","iopub.execute_input":"2024-05-30T06:21:05.447737Z","iopub.status.idle":"2024-05-30T06:21:05.457827Z","shell.execute_reply.started":"2024-05-30T06:21:05.447703Z","shell.execute_reply":"2024-05-30T06:21:05.456880Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"train(model, train_dataloader, epochs, optimizer, scheduler, device)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T08:10:02.809519Z","iopub.execute_input":"2024-05-30T08:10:02.809909Z","iopub.status.idle":"2024-05-30T09:04:00.283892Z","shell.execute_reply.started":"2024-05-30T08:10:02.809877Z","shell.execute_reply":"2024-05-30T09:04:00.282621Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 2634/2634 [17:23<00:00,  2.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Average Training Loss: 0.3529166090885572, Train Accuracy: 0.9015662078785003\nEpoch 2/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 2634/2634 [17:22<00:00,  2.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Average Training Loss: 0.3560447997088992, Train Accuracy: 0.8989084005695301\nEpoch 3/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 2634/2634 [17:23<00:00,  2.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Average Training Loss: 0.360478022446235, Train Accuracy: 0.897437114380636\nEpoch 4/5\n","output_type":"stream"},{"name":"stderr","text":"Training:  10%|█         | 271/2634 [01:47<15:39,  2.51it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[84], line 26\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, epochs, optimizer, scheduler, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     25\u001b[0m     preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     correct_preds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     total_preds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_labels)\n\u001b[1;32m     29\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"def evaluate_model(model, dataloader, device):\n    model.eval()\n    predictions = []\n    true_labels = []\n\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n            batch_input_ids, batch_attention_masks, batch_labels = tuple(t.to(device) for t in batch)\n\n            outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_masks)\n            logits = outputs.logits\n            predictions.extend(torch.argmax(logits, dim=1).tolist())\n            true_labels.extend(batch_labels.tolist())\n\n    predictions = np.array(predictions)\n    true_labels = np.array(true_labels)\n\n    accuracy = accuracy_score(true_labels, predictions)\n    f1 = f1_score(true_labels, predictions, average='weighted')\n    cm = confusion_matrix(true_labels, predictions)\n\n    print(f'Accuracy: {accuracy}')\n    print(f'F1 Score: {f1}')\n    print(f'Confusion Matrix:\\n {cm}')\n\n    # Log các thang đo vào wandb\n    wandb.log({\n        \"eval_accuracy\": accuracy,\n        \"eval_f1_score\": f1,\n        \"eval_confusion_matrix\": wandb.plot.confusion_matrix(\n            probs=None,\n            y_true=true_labels,\n            preds=predictions,\n            class_names=[str(i) for i in range(len(cm))]\n        )\n    })\n\n    return accuracy, f1, cm","metadata":{"execution":{"iopub.status.busy":"2024-05-30T09:04:02.705517Z","iopub.execute_input":"2024-05-30T09:04:02.706348Z","iopub.status.idle":"2024-05-30T09:04:02.716769Z","shell.execute_reply.started":"2024-05-30T09:04:02.706316Z","shell.execute_reply":"2024-05-30T09:04:02.715650Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"evaluate_model(model, val_dataloader, device='cuda')","metadata":{"execution":{"iopub.status.busy":"2024-05-30T09:04:04.972330Z","iopub.execute_input":"2024-05-30T09:04:04.972746Z","iopub.status.idle":"2024-05-30T09:04:52.524627Z","shell.execute_reply.started":"2024-05-30T09:04:04.972718Z","shell.execute_reply":"2024-05-30T09:04:52.523635Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 340/340 [00:47<00:00,  7.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.6915715863084284\nF1 Score: 0.6909239201281032\nConfusion Matrix:\n [[1423  412]\n [ 426  456]]\n","output_type":"stream"},{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"(0.6915715863084284,\n 0.6909239201281032,\n array([[1423,  412],\n        [ 426,  456]]))"},"metadata":{}}]},{"cell_type":"code","source":"checkpoint_path = \"./results/checkpoint-train\"\nmodel.save_pretrained(checkpoint_path)\ntokenizer.save_pretrained(checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T07:48:50.878549Z","iopub.execute_input":"2024-05-30T07:48:50.879276Z","iopub.status.idle":"2024-05-30T07:48:51.805685Z","shell.execute_reply.started":"2024-05-30T07:48:50.879247Z","shell.execute_reply":"2024-05-30T07:48:51.804705Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"('./results/checkpoint-train/tokenizer_config.json',\n './results/checkpoint-train/special_tokens_map.json',\n './results/checkpoint-train/vocab.txt',\n './results/checkpoint-train/bpe.codes',\n './results/checkpoint-train/added_tokens.json')"},"metadata":{}}]}]}