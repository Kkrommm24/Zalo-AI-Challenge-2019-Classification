{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4724979,"sourceType":"datasetVersion","datasetId":2733983},{"sourceId":8215012,"sourceType":"datasetVersion","datasetId":4869078},{"sourceId":8483734,"sourceType":"datasetVersion","datasetId":5060419},{"sourceId":60538,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":50628},{"sourceId":60648,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":50628}],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Pretrain with MLM and Fine-tune with SequenceClassification","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install transformers\n!pip install --upgrade torch torchvision torchaudio\n!pip install wandb\n!pip install scikit-learn\n!pip install numpy","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:45:21.546974Z","iopub.execute_input":"2024-06-04T11:45:21.547613Z","iopub.status.idle":"2024-06-04T11:46:24.751645Z","shell.execute_reply.started":"2024-06-04T11:45:21.547582Z","shell.execute_reply":"2024-06-04T11:46:24.750534Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.3.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.18.0)\nRequirement already satisfied: torchaudio in /opt/conda/lib/python3.10/site-packages (2.3.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.3.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch) (12.1.105)\nRequirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.10/site-packages (from torch) (2.3.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.17.0)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (4.2.2)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.3.1)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport json\nimport torch\nimport random\nimport numpy as np\nimport torch.nn as nn\nimport wandb\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, get_linear_schedule_with_warmup, AutoModelForMaskedLM, AutoModel, DataCollatorForLanguageModeling\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, Dataset\nfrom imblearn.over_sampling import RandomOverSampler\nfrom torch.optim import Adam\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:24.754377Z","iopub.execute_input":"2024-06-04T11:46:24.754804Z","iopub.status.idle":"2024-06-04T11:46:24.764747Z","shell.execute_reply.started":"2024-06-04T11:46:24.754764Z","shell.execute_reply":"2024-06-04T11:46:24.763686Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"wandb.login(key=\"9b49f600300d891290c544a9d0580ec7b7185a34\")\nwandb.init(project='zaloqa-bert', entity='hdghung2912')","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:24.766133Z","iopub.execute_input":"2024-06-04T11:46:24.767588Z","iopub.status.idle":"2024-06-04T11:46:46.143769Z","shell.execute_reply.started":"2024-06-04T11:46:24.767552Z","shell.execute_reply":"2024-06-04T11:46:46.142856Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:8ch9pzgk) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f0a14da61e844bdb4660de6359936b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>▁▇█</td></tr><tr><td>Train Loss</td><td>█▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>0.99767</td></tr><tr><td>Train Loss</td><td>0.00988</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">apricot-rain-59</strong> at: <a href='https://wandb.ai/hdghung2912/zaloqa-bert/runs/8ch9pzgk' target=\"_blank\">https://wandb.ai/hdghung2912/zaloqa-bert/runs/8ch9pzgk</a><br/> View project at: <a href='https://wandb.ai/hdghung2912/zaloqa-bert' target=\"_blank\">https://wandb.ai/hdghung2912/zaloqa-bert</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20240604_104505-8ch9pzgk/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:8ch9pzgk). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240604_114624-zqbbx91k</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/hdghung2912/zaloqa-bert/runs/zqbbx91k' target=\"_blank\">royal-cloud-60</a></strong> to <a href='https://wandb.ai/hdghung2912/zaloqa-bert' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/hdghung2912/zaloqa-bert' target=\"_blank\">https://wandb.ai/hdghung2912/zaloqa-bert</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/hdghung2912/zaloqa-bert/runs/zqbbx91k' target=\"_blank\">https://wandb.ai/hdghung2912/zaloqa-bert/runs/zqbbx91k</a>"},"metadata":{}},{"execution_count":47,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/hdghung2912/zaloqa-bert/runs/zqbbx91k?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7ac396b66980>"},"metadata":{}}]},{"cell_type":"code","source":"with open('/kaggle/input/uit-visquad/visquad_train.json', 'r', encoding='utf-8') as f:\n    input_data = json.load(f)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:46.144904Z","iopub.execute_input":"2024-06-04T11:46:46.145176Z","iopub.status.idle":"2024-06-04T11:46:46.876404Z","shell.execute_reply.started":"2024-06-04T11:46:46.145152Z","shell.execute_reply":"2024-06-04T11:46:46.875630Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"def is_answer_correct(context, answer):\n    return answer in context","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:46.878805Z","iopub.execute_input":"2024-06-04T11:46:46.879093Z","iopub.status.idle":"2024-06-04T11:46:46.883414Z","shell.execute_reply.started":"2024-06-04T11:46:46.879070Z","shell.execute_reply":"2024-06-04T11:46:46.882455Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"pretrain_data = []\nfor item in input_data['data']:\n    for paragraph in item['paragraphs']:\n        context = paragraph.get('context', \"\")\n        for qa in paragraph['qas']:\n            question = qa.get('question', \"\")\n            if 'answers' in qa:\n                for answer in qa['answers']:\n                    answer_text = answer.get('text', \"\")\n                    label = is_answer_correct(context, answer_text)\n                    pretrain_data.append({\n                        \"question\": question,\n                        \"text\": context,\n                        \"label\": label\n                    })\n            if 'plausible_answers' in qa:\n                for answer in qa['plausible_answers']:\n                    answer_text = answer.get('text', \"\")\n                    label = False  # Plausible answers are considered as false\n                    pretrain_data.append({\n                        \"question\": question,\n                        \"text\": context,\n                        \"label\": label\n                    })\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:46.884469Z","iopub.execute_input":"2024-06-04T11:46:46.884769Z","iopub.status.idle":"2024-06-04T11:46:46.942963Z","shell.execute_reply.started":"2024-06-04T11:46:46.884746Z","shell.execute_reply":"2024-06-04T11:46:46.942110Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"for i in range(min(5, len(pretrain_data))):\n    print(json.dumps(pretrain_data[i], ensure_ascii=False, indent=4))","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:46.944031Z","iopub.execute_input":"2024-06-04T11:46:46.944293Z","iopub.status.idle":"2024-06-04T11:46:46.951192Z","shell.execute_reply.started":"2024-06-04T11:46:46.944271Z","shell.execute_reply":"2024-06-04T11:46:46.950325Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"{\n    \"question\": \"Tên gọi nào được Phạm Văn Đồng sử dụng khi làm Phó chủ nhiệm cơ quan Biện sự xứ tại Quế Lâm?\",\n    \"text\": \"Phạm Văn Đồng (1 tháng 3 năm 1906 – 29 tháng 4 năm 2000) là Thủ tướng đầu tiên của nước Cộng hòa Xã hội chủ nghĩa Việt Nam từ năm 1976 (từ năm 1981 gọi là Chủ tịch Hội đồng Bộ trưởng) cho đến khi nghỉ hưu năm 1987. Trước đó ông từng giữ chức vụ Thủ tướng Chính phủ Việt Nam Dân chủ Cộng hòa từ năm 1955 đến năm 1976. Ông là vị Thủ tướng Việt Nam tại vị lâu nhất (1955–1987). Ông là học trò, cộng sự của Chủ tịch Hồ Chí Minh. Ông có tên gọi thân mật là Tô, đây từng là bí danh của ông. Ông còn có tên gọi là Lâm Bá Kiệt khi làm Phó chủ nhiệm cơ quan Biện sự xứ tại Quế Lâm (Chủ nhiệm là Hồ Học Lãm).\",\n    \"label\": true\n}\n{\n    \"question\": \"Phạm Văn Đồng giữ chức vụ gì trong bộ máy Nhà nước Cộng hòa Xã hội chủ nghĩa Việt Nam?\",\n    \"text\": \"Phạm Văn Đồng (1 tháng 3 năm 1906 – 29 tháng 4 năm 2000) là Thủ tướng đầu tiên của nước Cộng hòa Xã hội chủ nghĩa Việt Nam từ năm 1976 (từ năm 1981 gọi là Chủ tịch Hội đồng Bộ trưởng) cho đến khi nghỉ hưu năm 1987. Trước đó ông từng giữ chức vụ Thủ tướng Chính phủ Việt Nam Dân chủ Cộng hòa từ năm 1955 đến năm 1976. Ông là vị Thủ tướng Việt Nam tại vị lâu nhất (1955–1987). Ông là học trò, cộng sự của Chủ tịch Hồ Chí Minh. Ông có tên gọi thân mật là Tô, đây từng là bí danh của ông. Ông còn có tên gọi là Lâm Bá Kiệt khi làm Phó chủ nhiệm cơ quan Biện sự xứ tại Quế Lâm (Chủ nhiệm là Hồ Học Lãm).\",\n    \"label\": true\n}\n{\n    \"question\": \"Giai đoạn năm 1955-1976, Phạm Văn Đồng nắm giữ chức vụ gì?\",\n    \"text\": \"Phạm Văn Đồng (1 tháng 3 năm 1906 – 29 tháng 4 năm 2000) là Thủ tướng đầu tiên của nước Cộng hòa Xã hội chủ nghĩa Việt Nam từ năm 1976 (từ năm 1981 gọi là Chủ tịch Hội đồng Bộ trưởng) cho đến khi nghỉ hưu năm 1987. Trước đó ông từng giữ chức vụ Thủ tướng Chính phủ Việt Nam Dân chủ Cộng hòa từ năm 1955 đến năm 1976. Ông là vị Thủ tướng Việt Nam tại vị lâu nhất (1955–1987). Ông là học trò, cộng sự của Chủ tịch Hồ Chí Minh. Ông có tên gọi thân mật là Tô, đây từng là bí danh của ông. Ông còn có tên gọi là Lâm Bá Kiệt khi làm Phó chủ nhiệm cơ quan Biện sự xứ tại Quế Lâm (Chủ nhiệm là Hồ Học Lãm).\",\n    \"label\": true\n}\n{\n    \"question\": \"Tên gọi nào được Phạm Văn Đồng sử dụng trước khi làm Phó chủ nhiệm cơ quan Biện sự xứ tại Quế Lâm?\",\n    \"text\": \"Phạm Văn Đồng (1 tháng 3 năm 1906 – 29 tháng 4 năm 2000) là Thủ tướng đầu tiên của nước Cộng hòa Xã hội chủ nghĩa Việt Nam từ năm 1976 (từ năm 1981 gọi là Chủ tịch Hội đồng Bộ trưởng) cho đến khi nghỉ hưu năm 1987. Trước đó ông từng giữ chức vụ Thủ tướng Chính phủ Việt Nam Dân chủ Cộng hòa từ năm 1955 đến năm 1976. Ông là vị Thủ tướng Việt Nam tại vị lâu nhất (1955–1987). Ông là học trò, cộng sự của Chủ tịch Hồ Chí Minh. Ông có tên gọi thân mật là Tô, đây từng là bí danh của ông. Ông còn có tên gọi là Lâm Bá Kiệt khi làm Phó chủ nhiệm cơ quan Biện sự xứ tại Quế Lâm (Chủ nhiệm là Hồ Học Lãm).\",\n    \"label\": false\n}\n{\n    \"question\": \"Hồ Học Lãm giữ chức vụ gì trong bộ máy Nhà nước Cộng hòa Xã hội chủ nghĩa Việt Nam?\",\n    \"text\": \"Phạm Văn Đồng (1 tháng 3 năm 1906 – 29 tháng 4 năm 2000) là Thủ tướng đầu tiên của nước Cộng hòa Xã hội chủ nghĩa Việt Nam từ năm 1976 (từ năm 1981 gọi là Chủ tịch Hội đồng Bộ trưởng) cho đến khi nghỉ hưu năm 1987. Trước đó ông từng giữ chức vụ Thủ tướng Chính phủ Việt Nam Dân chủ Cộng hòa từ năm 1955 đến năm 1976. Ông là vị Thủ tướng Việt Nam tại vị lâu nhất (1955–1987). Ông là học trò, cộng sự của Chủ tịch Hồ Chí Minh. Ông có tên gọi thân mật là Tô, đây từng là bí danh của ông. Ông còn có tên gọi là Lâm Bá Kiệt khi làm Phó chủ nhiệm cơ quan Biện sự xứ tại Quế Lâm (Chủ nhiệm là Hồ Học Lãm).\",\n    \"label\": false\n}\n","output_type":"stream"}]},{"cell_type":"code","source":"pretrain_file_path = '/kaggle/working/visquad_true_false.json'\n\n# Tạo thư mục nếu chưa tồn tại\nos.makedirs(os.path.dirname(pretrain_file_path), exist_ok=True)\n\n# Lưu dữ liệu mới vào file JSON\nwith open(pretrain_file_path, 'w', encoding='utf-8') as f:\n    f.write(json.dumps(pretrain_data, ensure_ascii=False, indent=4))","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:46.952200Z","iopub.execute_input":"2024-06-04T11:46:46.952446Z","iopub.status.idle":"2024-06-04T11:46:47.637103Z","shell.execute_reply.started":"2024-06-04T11:46:46.952426Z","shell.execute_reply":"2024-06-04T11:46:47.636130Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# Load the data from train.json\nwith open('/kaggle/input/traintest/train.json', 'r', encoding='utf-8') as file:\n    data = json.load(file)\n\n# Split the data into train and test sets (85% train, 15% test)\ntrain_data, test_data = train_test_split(data, test_size=0.15, random_state=42)\n\n# Save the train and test data to separate files\nwith open('train_split.json', 'w', encoding='utf-8') as train_file:\n    json.dump(train_data, train_file, ensure_ascii=False, indent=4)\n\nwith open('test_split.json', 'w', encoding='utf-8') as test_file:\n    json.dump(test_data, test_file, ensure_ascii=False, indent=4)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:47.638371Z","iopub.execute_input":"2024-06-04T11:46:47.638770Z","iopub.status.idle":"2024-06-04T11:46:48.178474Z","shell.execute_reply.started":"2024-06-04T11:46:47.638720Z","shell.execute_reply":"2024-06-04T11:46:48.177538Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# Đọc dữ liệu từ tập tin train_split.json vào biến train_data\nwith open('train_split.json', 'r', encoding='utf-8') as train_file:\n    train_data = json.load(train_file)\n\n# Đọc dữ liệu từ tập tin test_split.json vào biến test_data\nwith open('test_split.json', 'r', encoding='utf-8') as test_file:\n    test_data = json.load(test_file)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:48.179798Z","iopub.execute_input":"2024-06-04T11:46:48.180469Z","iopub.status.idle":"2024-06-04T11:46:48.346365Z","shell.execute_reply.started":"2024-06-04T11:46:48.180435Z","shell.execute_reply":"2024-06-04T11:46:48.345624Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"pretrain_model = AutoModelForMaskedLM.from_pretrained(\"vinai/phobert-base-v2\")\ntokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:48.347682Z","iopub.execute_input":"2024-06-04T11:46:48.348109Z","iopub.status.idle":"2024-06-04T11:46:49.718792Z","shell.execute_reply.started":"2024-06-04T11:46:48.348076Z","shell.execute_reply":"2024-06-04T11:46:49.717900Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"class MLMPretrainDataset(Dataset):\n    def __init__(self, data, tokenizer, max_length=256):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        question = self.data[idx][\"question\"]\n        text = self.data[idx][\"text\"]\n        input_text = question + \" \" + text\n        encoding = self.tokenizer(\n            input_text,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors=\"pt\"  # Sử dụng return_tensors=\"pt\" để trả về tensor\n        )\n        input_ids = encoding['input_ids'].squeeze()\n        attention_mask = encoding['attention_mask'].squeeze()\n        \n        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:49.720610Z","iopub.execute_input":"2024-06-04T11:46:49.721026Z","iopub.status.idle":"2024-06-04T11:46:49.729951Z","shell.execute_reply.started":"2024-06-04T11:46:49.720987Z","shell.execute_reply":"2024-06-04T11:46:49.728946Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\ndataset = MLMPretrainDataset(pretrain_data, tokenizer, max_length=256)\n\n# Data collator để chuẩn bị batch\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)\n\ndataloader = DataLoader(dataset, batch_size=16, collate_fn=data_collator)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:49.731329Z","iopub.execute_input":"2024-06-04T11:46:49.731636Z","iopub.status.idle":"2024-06-04T11:46:50.160501Z","shell.execute_reply.started":"2024-06-04T11:46:49.731611Z","shell.execute_reply":"2024-06-04T11:46:50.159737Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"for i, batch in enumerate(dataloader):\n    input_ids = batch[\"input_ids\"]\n    attention_mask = batch[\"attention_mask\"]\n    print(f\"Batch {i + 1}:\")\n    print(\"Input IDs:\", input_ids)\n    print(\"Attention Mask:\", attention_mask)\n    if i == 2:  # Print the first 3 batches\n        break\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:50.165818Z","iopub.execute_input":"2024-06-04T11:46:50.166082Z","iopub.status.idle":"2024-06-04T11:46:50.294124Z","shell.execute_reply.started":"2024-06-04T11:46:50.166060Z","shell.execute_reply":"2024-06-04T11:46:50.293246Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Batch 1:\nInput IDs: tensor([[    0,  4473,   328,  ...,     1,     1,     1],\n        [    0, 49517,  2965,  ...,     1,     1,     1],\n        [    0, 26268,   687,  ...,     1,     1,     1],\n        ...,\n        [    0,  6713,  2965,  ...,     1,     1,     1],\n        [    0, 25254,   326,  ...,     1,     1,     1],\n        [    0,   680,  5444,  ...,     1,     1,     1]])\nAttention Mask: tensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0]])\nBatch 2:\nInput IDs: tensor([[    0,   268, 13466,  ...,     1,     1,     1],\n        [    0, 24664,  6035,  ...,     1,     1,     1],\n        [    0,   382,   423,  ...,     1,     1,     1],\n        ...,\n        [    0,  7657,  9901,  ...,     1,     1,     1],\n        [    0,   146,  1941,  ...,     1,     1,     1],\n        [    0,  6081,   212,  ...,     1,     1,     1]])\nAttention Mask: tensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0]])\nBatch 3:\nInput IDs: tensor([[    0,  7657,  9901,  ...,     1,     1,     1],\n        [    0,  4190,   229,  ...,     1,     1,     1],\n        [    0,  6081,   212,  ...,     1,     1,     1],\n        ...,\n        [    0, 15556, 12351,  ...,    53,    26,     2],\n        [    0, 15556, 12351,  ...,    53, 64000,     2],\n        [    0,  2679,     8,  ...,    10,  4623,     2]])\nAttention Mask: tensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1]])\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\npretrain_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:50.295186Z","iopub.execute_input":"2024-06-04T11:46:50.295449Z","iopub.status.idle":"2024-06-04T11:46:50.448471Z","shell.execute_reply.started":"2024-06-04T11:46:50.295427Z","shell.execute_reply":"2024-06-04T11:46:50.447645Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"RobertaForMaskedLM(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n      (position_embeddings): Embedding(258, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (lm_head): RobertaLMHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    (decoder): Linear(in_features=768, out_features=64001, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = Adam(pretrain_model.parameters(), lr=5e-5)\nepochs = 5\ntotal_steps = len(dataloader) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:50.449715Z","iopub.execute_input":"2024-06-04T11:46:50.450093Z","iopub.status.idle":"2024-06-04T11:46:50.456282Z","shell.execute_reply.started":"2024-06-04T11:46:50.450057Z","shell.execute_reply":"2024-06-04T11:46:50.455413Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"def pretrain(model, dataloader, optimizer, device, epochs, checkpoint_dir):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        for step, batch in enumerate(tqdm(dataloader, desc=f\"Pretrain Epoch {epoch + 1}/{epochs}\")):\n            batch = {k: v.to(device) for k, v in batch.items()}\n            optimizer.zero_grad()\n            outputs = model(**batch)\n            loss = outputs.loss\n            total_loss += loss.item()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n\n        avg_train_loss = total_loss / len(dataloader)\n        print(f\"Pretrain Epoch {epoch + 1}, Average Training Loss: {avg_train_loss}\")\n        \n        wandb.log({\"pretrain_batch_loss\": loss.item()})\n        \n        os.makedirs(checkpoint_dir, exist_ok=True)\n        checkpoint_path = f\"{checkpoint_dir}/checkpoint_epoch_{epoch + 1}.pt\"\n        torch.save(model.state_dict(), checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:50.457605Z","iopub.execute_input":"2024-06-04T11:46:50.457866Z","iopub.status.idle":"2024-06-04T11:46:50.467080Z","shell.execute_reply.started":"2024-06-04T11:46:50.457844Z","shell.execute_reply":"2024-06-04T11:46:50.466272Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"checkpoint_dir = './checkpoints'\n#pretrain(pretrain_model, dataloader, optimizer, device, epochs, checkpoint_dir)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:50.468376Z","iopub.execute_input":"2024-06-04T11:46:50.469057Z","iopub.status.idle":"2024-06-04T11:46:50.477610Z","shell.execute_reply.started":"2024-06-04T11:46:50.469026Z","shell.execute_reply":"2024-06-04T11:46:50.476646Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"pretrain_checkpoint_dir = './pretrain_checkpoint'\nos.makedirs(pretrain_checkpoint_dir, exist_ok=True)\npretrain_model.save_pretrained(pretrain_checkpoint_dir)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:50.478712Z","iopub.execute_input":"2024-06-04T11:46:50.479047Z","iopub.status.idle":"2024-06-04T11:46:51.746528Z","shell.execute_reply.started":"2024-06-04T11:46:50.479016Z","shell.execute_reply":"2024-06-04T11:46:51.745548Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(data, tokenizer):\n    max_question_length = 64\n    max_text_length = 192\n    input_ids = []\n    attention_masks = []\n    labels = []\n\n    for sample in data:\n        question = sample['question']\n        text = sample['text']\n        label = sample['label']\n        \n        encoded_question = tokenizer.encode_plus(\n            question,\n            add_special_tokens=True,\n            truncation=True,\n            max_length=max_question_length,\n            padding='max_length',\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n\n        encoded_text = tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            truncation=True,\n            max_length=max_text_length,\n            padding='max_length',\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n\n        combined_input_ids = torch.cat((encoded_question['input_ids'], encoded_text['input_ids']), dim=1)\n        combined_attention_mask = torch.cat((encoded_question['attention_mask'], encoded_text['attention_mask']), dim=1)\n\n        input_ids.append(combined_input_ids)\n        attention_masks.append(combined_attention_mask)\n        labels.append(1 if label else 0)\n\n    input_ids = torch.cat(input_ids, dim=0)\n    attention_masks = torch.cat(attention_masks, dim=0)\n    labels = torch.tensor(labels)\n\n    print(f\"Pretrained input_ids shape: {input_ids.shape}\")\n    print(f\"Pretrained attention_masks shape: {attention_masks.shape}\")\n    print(f\"Pretrained labels shape: {labels.shape}\")\n\n    return input_ids, attention_masks, labels","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:51.747864Z","iopub.execute_input":"2024-06-04T11:46:51.748159Z","iopub.status.idle":"2024-06-04T11:46:51.758559Z","shell.execute_reply.started":"2024-06-04T11:46:51.748136Z","shell.execute_reply":"2024-06-04T11:46:51.757663Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"X = [{'question': sample['question'], 'text': sample['text']} for sample in data]\ny = [sample['label'] for sample in data]\n\n# Chia dữ liệu thành tập huấn luyện và tập validation (85-15)\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15, random_state=42)\n\n# Tạo một RandomOverSampler\nros = RandomOverSampler(random_state=0)\n\n# Resample tập huấn luyện\nX_train_array = np.array([[sample['question'], sample['text']] for sample in X_train])\nX_train_resampled, y_train_resampled = ros.fit_resample(X_train_array, y_train)\n\n# Đảm bảo X_train_resampled và y_train_resampled có cùng số lượng mẫu\nassert len(X_train_resampled) == len(y_train_resampled)\n\n# In ra số lượng nhãn true và false trong tập huấn luyện sau khi resample\nnum_true_resampled_train = sum(1 for label in y_train_resampled if label)\nnum_false_resampled_train = len(y_train_resampled) - num_true_resampled_train\nprint(\"Resampled Train - Number of true labels:\", num_true_resampled_train)\nprint(\"Resampled Train - Number of false labels:\", num_false_resampled_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:51.759772Z","iopub.execute_input":"2024-06-04T11:46:51.760405Z","iopub.status.idle":"2024-06-04T11:46:52.765177Z","shell.execute_reply.started":"2024-06-04T11:46:51.760374Z","shell.execute_reply":"2024-06-04T11:46:52.764220Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Resampled Train - Number of true labels: 10535\nResampled Train - Number of false labels: 10535\n","output_type":"stream"}]},{"cell_type":"code","source":"resampled_data = [{'question': X_train_resampled[i, 0], 'text': X_train_resampled[i, 1], 'label': y_train_resampled[i]} for i in range(len(X_train_resampled))]","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:52.766592Z","iopub.execute_input":"2024-06-04T11:46:52.767299Z","iopub.status.idle":"2024-06-04T11:46:53.068653Z","shell.execute_reply.started":"2024-06-04T11:46:52.767262Z","shell.execute_reply":"2024-06-04T11:46:53.067879Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    print(f'Question: {X_train_resampled[i, 0]}')\n    print(f'Text: {X_train_resampled[i, 1]}')\n    print(f'Label: {y_train_resampled[i]}')\n    print('---')","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:53.070097Z","iopub.execute_input":"2024-06-04T11:46:53.070396Z","iopub.status.idle":"2024-06-04T11:46:53.080096Z","shell.execute_reply.started":"2024-06-04T11:46:53.070373Z","shell.execute_reply":"2024-06-04T11:46:53.079014Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Question: Sông Nin đổ ra biển nào\nText: Sông Luỹ đổ ra biển ở cửa biển tại thị trấn Phan Rí\nLabel: False\n---\nQuestion: Tên gọi Nhật Bản nghĩa là gì\nText: Từ ghép này có nghĩa là \" nguồn gốc của mặt trời \" hoặc \" nơi mặt trời mọc \" ( từ quan điểm từ Trung Quốc , mặt trời mọc từ phía Nhật Bản ) ; nó là một nguồn cơ sở cho mô tả của phương Tây về Nhật Bản như là \" Vùng đất Mặt trời mọc \" ( \" Land of the Rising Sun \" ) .\nLabel: True\n---\nQuestion: Dầu mỏ có màu gì\nText: Loại dầu khoáng này là dầu trong suốt , không màu bao gồm chủ yếu là ankan và cycloankan , liên quan đến thạch dầu mỏ .\nLabel: False\n---\nQuestion: Huyện đảo Phú Quốc có diện tích bao nhiêu\nText: Hồ tiêu Phú Quốc là một loại gia vị được coi là đặc sản của huyện đảo Phú Quốc thuộc Tỉnh Kiên Giang , Việt Nam .\nLabel: False\n---\nQuestion: Cộng hoà Ireland có biên giới trên bộ với quốc gia nào\nText: Ireland là một quốc gia thành viên Liên minh châu Âu từ năm 1973 , song lựa chọn duy trì bên ngoài khu vực Schengen . Công dân Anh Quốc có thể tự do nhập cảnh Cộng hoà Ireland mà không cần hộ chiếu do hai bên có biên giới mở .\nLabel: False\n---\n","output_type":"stream"}]},{"cell_type":"code","source":"val_data = [{'question': sample['question'], 'text': sample['text'], 'label': label} for sample, label in zip(X_val, y_val)]","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:53.081356Z","iopub.execute_input":"2024-06-04T11:46:53.081711Z","iopub.status.idle":"2024-06-04T11:46:53.090335Z","shell.execute_reply.started":"2024-06-04T11:46:53.081681Z","shell.execute_reply":"2024-06-04T11:46:53.089383Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"for i in range(5):\n    print(f'Question: {val_data[i][\"question\"]}')\n    print(f'Text: {val_data[i][\"text\"]}')\n    print(f'Label: {val_data[i][\"label\"]}')\n    print('---')","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:53.091588Z","iopub.execute_input":"2024-06-04T11:46:53.091857Z","iopub.status.idle":"2024-06-04T11:46:53.102724Z","shell.execute_reply.started":"2024-06-04T11:46:53.091835Z","shell.execute_reply":"2024-06-04T11:46:53.101262Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Question: Lê Lợi với Lê Lai có quan hệ gì\nText: Lê Thái Tổ ở ngôi được 5 năm thì qua đời vào ngày 22 tháng 8 âm lịch (7 tháng 9 dương lịch) năm Quý Sửu (1433), hưởng dương 49 tuổi. Vì nhớ công Lê Lai chết thay cho mình ở núi Chí Linh trước kia, ông dặn lại đời sau phải giỗ Lê Lai trước khi giỗ ông một ngày. Bởi thế đời sau truyền lại câu: \"Hăm mốt Lê Lai, hăm hai Lê Lợi.\"\nLabel: False\n---\nQuestion: ai là phó bí thư hiện tại của Đà Nẵng\nText: Ngày 15 tháng 7 năm 2013 , Thành uỷ Đà Nẵng công bố quyết định số 7340 / QĐ-TU thành lập Ban Nội chính Thành uỷ Đà Nẵng . Ông Trần Thanh Vân , lúc này là Thành uỷ viên Thành uỷ Đà Nẵng , Viện trưởng Viện kiểm sát nhân dân thành phố Đà Nẵng , được điều động , bổ nhiệm làm Trưởng Ban Nội chính Thành uỷ Đà Nẵng nhiệm kì 5 năm , hai Phó ban là Nhật Thành , Phó Trưởng Ban thường trực Ban chỉ đạo Phòng chống tham nhũng thành phố Đà Nẵng và ông Phạm Hà Bắc , Phó Trưởng Ban chỉ đạo phòng chống tham nhũng thành phố Đà Nẵng .\nLabel: False\n---\nQuestion: Ai là tác giả của bài Hịch tướng sĩ\nText: Ngô Tất Tố viết rằng bài Dụ chư tỳ tướng hịch văn cho thấy, không những Hưng Đạo Vương là võ tướng mà ông còn có tài học vấn, đọc nhiều sách và thông hiểu nhiều điển tích cổ kim.\nLabel: False\n---\nQuestion: Quang Trung mất vào ngày tháng năm nào\nText: Dương Quang Trung (sinh ngày 03 tháng 9 năm 1928 mất ngày 22 tháng 6 năm 2013) biệt hiệu Tư Trung là một bác sĩ người Việt Nam.\nLabel: False\n---\nQuestion: Tôn Trung Sơn nhậm chức tổng thống năm nào\nText: Đến mùa đông Tưởng Giới Thạch tuân lệnh nhậm chức Tham mưu trưởng Quân đoàn 2 Đông lộ thảo tặc quân , đến Phúc Kiến lập kế dẹp loạn . Lúc đó , Tôn Trung Sơn phái Tưởng Giới Thạch đi Phúc Kiến , lập liên hệ cùng An Phúc hệ quân phiệt ; dưới sự bang trợ của họ , Tôn Trung Sơn trở về Quảng Châu vào năm 1923 .\nLabel: False\n---\n","output_type":"stream"}]},{"cell_type":"code","source":"checkpoint_pretrain = '/kaggle/input/uit-mlm/transformers/uit-mlm/1/checkpoint-pretrained'","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:53.103984Z","iopub.execute_input":"2024-06-04T11:46:53.104312Z","iopub.status.idle":"2024-06-04T11:46:53.108330Z","shell.execute_reply.started":"2024-06-04T11:46:53.104283Z","shell.execute_reply":"2024-06-04T11:46:53.107535Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(checkpoint_pretrain, num_labels=2)\ntokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:53.109467Z","iopub.execute_input":"2024-06-04T11:46:53.109759Z","iopub.status.idle":"2024-06-04T11:46:53.762680Z","shell.execute_reply.started":"2024-06-04T11:46:53.109730Z","shell.execute_reply":"2024-06-04T11:46:53.761843Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/uit-mlm/transformers/uit-mlm/1/checkpoint-pretrained and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"train_input_ids, train_attention_masks, train_labels = preprocess_data(resampled_data, tokenizer)\nval_input_ids, val_attention_masks, val_labels = preprocess_data(val_data, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:46:53.763880Z","iopub.execute_input":"2024-06-04T11:46:53.764195Z","iopub.status.idle":"2024-06-04T11:47:18.212381Z","shell.execute_reply.started":"2024-06-04T11:46:53.764169Z","shell.execute_reply":"2024-06-04T11:47:18.211433Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"Pretrained input_ids shape: torch.Size([21070, 256])\nPretrained attention_masks shape: torch.Size([21070, 256])\nPretrained labels shape: torch.Size([21070])\nPretrained input_ids shape: torch.Size([2717, 256])\nPretrained attention_masks shape: torch.Size([2717, 256])\nPretrained labels shape: torch.Size([2717])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Tạo TensorDataset cho tập huấn luyện\ntrain_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n\n# Tạo DataLoader cho tập huấn luyện\ntrain_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=16)\n\n# Tạo TensorDataset cho tập validation\nval_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n\n# Tạo DataLoader cho tập validation\nval_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:47:18.213604Z","iopub.execute_input":"2024-06-04T11:47:18.213905Z","iopub.status.idle":"2024-06-04T11:47:18.219249Z","shell.execute_reply.started":"2024-06-04T11:47:18.213880Z","shell.execute_reply":"2024-06-04T11:47:18.218371Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"for batch in train_dataloader:\n    batch_input_ids, batch_attention_masks, batch_labels = batch\n    print(f\"Batch input_ids shape: {batch_input_ids.shape}\")\n    print(f\"Batch attention_masks shape: {batch_attention_masks.shape}\")\n    print(f\"Batch labels shape: {batch_labels.shape}\")\n    break","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:47:18.220570Z","iopub.execute_input":"2024-06-04T11:47:18.220906Z","iopub.status.idle":"2024-06-04T11:47:18.230803Z","shell.execute_reply.started":"2024-06-04T11:47:18.220873Z","shell.execute_reply":"2024-06-04T11:47:18.229885Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Batch input_ids shape: torch.Size([16, 256])\nBatch attention_masks shape: torch.Size([16, 256])\nBatch labels shape: torch.Size([16])\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:47:18.231883Z","iopub.execute_input":"2024-06-04T11:47:18.232144Z","iopub.status.idle":"2024-06-04T11:47:18.385888Z","shell.execute_reply.started":"2024-06-04T11:47:18.232122Z","shell.execute_reply":"2024-06-04T11:47:18.385015Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n      (position_embeddings): Embedding(258, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = Adam(model.parameters(), lr=2e-5)\ncriterion = nn.BCEWithLogitsLoss()","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:47:18.386865Z","iopub.execute_input":"2024-06-04T11:47:18.387136Z","iopub.status.idle":"2024-06-04T11:47:18.393006Z","shell.execute_reply.started":"2024-06-04T11:47:18.387113Z","shell.execute_reply":"2024-06-04T11:47:18.392148Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"epochs = 5\ntotal_steps = len(train_dataloader) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:47:18.394132Z","iopub.execute_input":"2024-06-04T11:47:18.394474Z","iopub.status.idle":"2024-06-04T11:47:18.401276Z","shell.execute_reply.started":"2024-06-04T11:47:18.394435Z","shell.execute_reply":"2024-06-04T11:47:18.400384Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"def train(model, train_dataloader, epochs, optimizer, scheduler, device, checkpoint_dir):\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch + 1}/{epochs}\")\n        model.train()\n        total_loss = 0\n        correct_preds = 0\n        total_preds = 0\n        # Sử dụng tqdm để hiển thị tiến trình huấn luyện\n        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training\")):\n            batch_input_ids, batch_attention_masks, batch_labels = tuple(t.to(device) for t in batch)\n            model.zero_grad()\n\n            # Sử dụng AutoModelForMaskedLM để tạo ra một instance của mô hình cho mỗi loại dữ liệu\n            outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_masks, labels=batch_labels)\n            loss = outputs.loss\n            total_loss += loss.item()\n            loss.backward()\n\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            scheduler.step()\n            \n            logits = outputs.logits\n            preds = torch.argmax(logits, dim=1)\n            correct_preds += torch.sum(preds == batch_labels).item()\n            total_preds += len(batch_labels)\n\n        avg_train_loss = total_loss / len(train_dataloader)\n        train_accuracy = correct_preds / total_preds\n        \n        print(f\"Epoch {epoch + 1}, Average Training Loss: {avg_train_loss}, Train Accuracy: {train_accuracy}\")\n        \n        wandb.log({\"Train Loss\": avg_train_loss, \"Train Accuracy\": train_accuracy})\n\n            \n        os.makedirs(checkpoint_dir, exist_ok=True)\n        # Lưu checkpoint sau mỗi epoch\n        checkpoint_path = f\"{checkpoint_dir}/checkpoint_epoch_{epoch + 1}.pt\"\n        torch.save(model.state_dict(), checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:47:18.402311Z","iopub.execute_input":"2024-06-04T11:47:18.402636Z","iopub.status.idle":"2024-06-04T11:47:18.413954Z","shell.execute_reply.started":"2024-06-04T11:47:18.402607Z","shell.execute_reply":"2024-06-04T11:47:18.413166Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = './results/checkpoint'","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:47:18.415082Z","iopub.execute_input":"2024-06-04T11:47:18.415640Z","iopub.status.idle":"2024-06-04T11:47:18.423348Z","shell.execute_reply.started":"2024-06-04T11:47:18.415610Z","shell.execute_reply":"2024-06-04T11:47:18.422614Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"checkpoint_dir = '/kaggle/input/uit-mlm/transformers/uit-mlm/2/checkpoint'\n\n# Tìm checkpoint cuối cùng\ncheckpoints = [f for f in os.listdir(checkpoint_dir) if f.startswith(\"checkpoint_epoch_\") and f.endswith(\".pt\")]\nif not checkpoints:\n    raise ValueError(\"No checkpoints found in directory.\")\n    \n# Sắp xếp và lấy checkpoint có số thứ tự lớn nhất\ncheckpoints.sort(key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))\nlast_checkpoint_path = os.path.join(checkpoint_dir, checkpoints[-1])\n\n# Nạp checkpoint vào mô hình\nmodel.load_state_dict(torch.load(last_checkpoint_path, map_location=torch.device('cpu')))\nprint(f\"Loaded checkpoint from {last_checkpoint_path}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:47:18.424369Z","iopub.execute_input":"2024-06-04T11:47:18.424725Z","iopub.status.idle":"2024-06-04T11:47:18.824196Z","shell.execute_reply.started":"2024-06-04T11:47:18.424694Z","shell.execute_reply":"2024-06-04T11:47:18.823324Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"Loaded checkpoint from /kaggle/input/uit-mlm/transformers/uit-mlm/2/checkpoint/checkpoint_epoch_7.pt\n","output_type":"stream"}]},{"cell_type":"code","source":"train(model, train_dataloader, epochs, optimizer, scheduler, device, checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:47:18.825308Z","iopub.execute_input":"2024-06-04T11:47:18.825624Z","iopub.status.idle":"2024-06-04T13:00:35.634748Z","shell.execute_reply.started":"2024-06-04T11:47:18.825600Z","shell.execute_reply":"2024-06-04T13:00:35.633807Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1317/1317 [14:39<00:00,  1.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Average Training Loss: 0.07666145806871184, Train Accuracy: 0.9832463217845278\nEpoch 2/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1317/1317 [14:38<00:00,  1.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Average Training Loss: 0.04442352545924977, Train Accuracy: 0.9906502135738016\nEpoch 3/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1317/1317 [14:38<00:00,  1.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Average Training Loss: 0.030552848703547703, Train Accuracy: 0.9937351684859991\nEpoch 4/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1317/1317 [14:37<00:00,  1.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Average Training Loss: 0.018740296039434456, Train Accuracy: 0.996203132415757\nEpoch 5/5\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 1317/1317 [14:37<00:00,  1.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Average Training Loss: 0.006504928956115276, Train Accuracy: 0.9986236355007119\n","output_type":"stream"}]},{"cell_type":"code","source":"def evaluate_model(model, dataloader, device):\n    model.eval()\n    predictions = []\n    true_labels = []\n\n    with torch.no_grad():\n        for batch in dataloader:            \n            batch_input_ids, batch_attention_masks, batch_labels = tuple(t.to(device) for t in batch)\n\n            outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_masks)\n            logits = outputs.logits\n            predictions.extend(torch.argmax(logits, dim=1).tolist())\n            true_labels.extend(batch_labels.tolist())\n\n    predictions = np.array(predictions)\n    true_labels = np.array(true_labels)\n\n    f1 = f1_score(true_labels, predictions)\n    cm = confusion_matrix(true_labels, predictions)\n\n    return f1, cm","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:00:35.636336Z","iopub.execute_input":"2024-06-04T13:00:35.636641Z","iopub.status.idle":"2024-06-04T13:00:35.643911Z","shell.execute_reply.started":"2024-06-04T13:00:35.636616Z","shell.execute_reply":"2024-06-04T13:00:35.642926Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"evaluate_model(model, val_dataloader, device)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:00:35.644978Z","iopub.execute_input":"2024-06-04T13:00:35.645238Z","iopub.status.idle":"2024-06-04T13:01:10.791634Z","shell.execute_reply.started":"2024-06-04T13:00:35.645216Z","shell.execute_reply":"2024-06-04T13:01:10.790725Z"},"trusted":true},"execution_count":83,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"(0.7944598337950138,\n array([[1629,  206],\n        [ 165,  717]]))"},"metadata":{}}]},{"cell_type":"code","source":"model.save_pretrained(checkpoint_path)\ntokenizer.save_pretrained(checkpoint_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:01:10.792848Z","iopub.execute_input":"2024-06-04T13:01:10.793157Z","iopub.status.idle":"2024-06-04T13:01:12.065872Z","shell.execute_reply.started":"2024-06-04T13:01:10.793130Z","shell.execute_reply":"2024-06-04T13:01:12.064649Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"('./results/checkpoint/tokenizer_config.json',\n './results/checkpoint/special_tokens_map.json',\n './results/checkpoint/vocab.txt',\n './results/checkpoint/bpe.codes',\n './results/checkpoint/added_tokens.json')"},"metadata":{}}]}]}